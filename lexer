
class Lexer:
    """Lexical analyzer to convert template text to tokens"""
    
    def __init__(self, source: str):
        self.source = source
        self.position = 0
        self.line = 1
        self.column = 1
        self.tokens: List[Token] = []
        
        self.keywords = {
            'if': TokenType.IF,
            'else': TokenType.ELSE,
            'elif': TokenType.ELIF,
            'endif': TokenType.ENDIF,
            'for': TokenType.FOR,
            'in': TokenType.IN,
            'endfor': TokenType.ENDFOR,
            'set': TokenType.SET,
        }
    
    def tokenize(self) -> List[Token]:
        """Convert text to list of tokens"""
        while self.position < len(self.source):
            # Skip whitespace
            if self.source[self.position].isspace():
                if self.source[self.position] == '\n':
                    self.line += 1
                    self.column = 1
                else:
                    self.column += 1
                self.position += 1
                continue
            
            # First check for special two-character symbols
            if self.position + 1 < len(self.source):
                two_char = self.source[self.position:self.position+2]
                if two_char == '{{':
                    token = Token(TokenType.EXPR_OPEN, two_char, self.line, self.column)
                    self.tokens.append(token)
                    self.position += 2
                    self.column += 2
                    continue
                elif two_char == '}}':
                    token = Token(TokenType.EXPR_CLOSE, two_char, self.line, self.column)
                    self.tokens.append(token)
                    self.position += 2
                    self.column += 2
                    continue
                elif two_char == '{%':
                    token = Token(TokenType.STMT_OPEN, two_char, self.line, self.column)
                    self.tokens.append(token)
                    self.position += 2
                    self.column += 2
                    continue
                elif two_char == '%}':
                    token = Token(TokenType.STMT_CLOSE, two_char, self.line, self.column)
                    self.tokens.append(token)
                    self.position += 2
                    self.column += 2
                    continue
                elif two_char == '/>':
                    token = Token(TokenType.TAG_SELF_CLOSE, two_char, self.line, self.column)
                    self.tokens.append(token)
                    self.position += 2
                    self.column += 2
                    continue
            
            # Check for single character symbols
            char = self.source[self.position]
            if char == '<':
                token = Token(TokenType.TAG_OPEN, char, self.line, self.column)
                self.tokens.append(token)
                self.position += 1
                self.column += 1
                continue
            elif char == '>':
                token = Token(TokenType.TAG_CLOSE, char, self.line, self.column)
                self.tokens.append(token)
                self.position += 1
                self.column += 1
                continue
            elif char == '|':
                token = Token(TokenType.PIPE, char, self.line, self.column)
                self.tokens.append(token)
                self.position += 1
                self.column += 1
                continue
            elif char == '(':
                token = Token(TokenType.L_PAREN, char, self.line, self.column)
                self.tokens.append(token)
                self.position += 1
                self.column += 1
                continue
            elif char == ')':
                token = Token(TokenType.R_PAREN, char, self.line, self.column)
                self.tokens.append(token)
                self.position += 1
                self.column += 1
                continue
            elif char == '=':
                token = Token(TokenType.ASSIGN, char, self.line, self.column)
                self.tokens.append(token)
                self.position += 1
                self.column += 1
                continue
            elif char == '.':
                token = Token(TokenType.DOT, char, self.line, self.column)
                self.tokens.append(token)
                self.position += 1
                self.column += 1
                continue
            elif char == ',':
                token = Token(TokenType.COMMA, char, self.line, self.column)
                self.tokens.append(token)
                self.position += 1
                self.column += 1
                continue
            elif char == ':':
                token = Token(TokenType.COLON, char, self.line, self.column)
                self.tokens.append(token)
                self.position += 1
                self.column += 1
                continue
            
            if char.isdigit():
                number = ''
                while self.position < len(self.source) and (self.source[self.position].isdigit() or 
                                                           (self.source[self.position] == '.' and 
                                                            self.position + 1 < len(self.source) and 
                                                            self.source[self.position + 1].isdigit())):
                    number += self.source[self.position]
                    self.position += 1
                
                token = Token(TokenType.NUMBER, number, self.line, self.column)
                self.tokens.append(token)
                self.column += len(number)
                continue
            
            # Handle identifiers and keywords
            if char.isalpha() or char == '_':
                identifier = ''
                while self.position < len(self.source) and (self.source[self.position].isalnum() or 
                                                           self.source[self.position] == '_'):
                    identifier += self.source[self.position]
                    self.position += 1
                
                # Check if it's a keyword
                token_type = TokenType.IDENTIFIER
                if identifier in self.keywords:
                    token_type = self.keywords[identifier]
                elif identifier in ['True', 'False']:
                    token_type = TokenType.BOOL
                
                token = Token(token_type, identifier, self.line, self.column)
                self.tokens.append(token)
                self.column += len(identifier)
                continue
            
            # Handle strings between quotes
            if char in ['"', "'"]:
                quote_char = char
                string_literal = quote_char
                self.position += 1
                self.column += 1
                
                while (self.position < len(self.source) and 
                       self.source[self.position] != quote_char):
                    # Handle escape characters
                    if self.source[self.position] == '\\' and self.position + 1 < len(self.source):
                        string_literal += self.source[self.position]
                        self.position += 1
                        self.column += 1
                    
                    string_literal += self.source[self.position]
                    self.position += 1
                    self.column += 1
                
                if self.position < len(self.source):
                    string_literal += self.source[self.position]  # Closing quote
                    self.position += 1
                    self.column += 1
                
                token = Token(TokenType.STRING, string_literal, self.line, self.column)
                self.tokens.append(token)
                continue
            
            # Handle multi-character operators
            multi_char_operators = ['==', '!=', '<=', '>=', 'and', 'or', 'not']
            matched_operator = False
            for op in multi_char_operators:
                if self.source.startswith(op, self.position):
                    token = Token(TokenType.OPERATOR, op, self.line, self.column)
                    self.tokens.append(token)
                    self.position += len(op)
                    self.column += len(op)
                    matched_operator = True
                    break
            
            if matched_operator:
                continue
            
            # Handle single-character operators
            single_char_operators = ['+', '-', '*', '/', '<', '>']
            if char in single_char_operators:
                token = Token(TokenType.OPERATOR, char, self.line, self.column)
                self.tokens.append(token)
                self.position += 1
                self.column += 1
                continue
            
            # Everything else is  text
            text = ''
            while (self.position < len(self.source) and 
                   not self.source[self.position].isspace() and
                   self.position + 1 < len(self.source) and
                   not self.source.startswith('{{', self.position) and
                   not self.source.startswith('{%', self.position) and
                   not self.source.startswith('}}', self.position) and
                   not self.source.startswith('%}', self.position) and
                   self.source[self.position] not in ['<', '>', '|', '(', ')', '=', '.', ',', ':', '+', '-', '*', '/']):
                text += self.source[self.position]
                self.position += 1
            
            if text:
                token = Token(TokenType.TEXT, text, self.line, self.column)
                self.tokens.append(token)
                self.column += len(text)
            else:
                # Unknown character - take only one character
                char = self.source[self.position]
                token = Token(TokenType.TEXT, char, self.line, self.column)
                self.tokens.append(token)
                self.position += 1
                self.column += 1
        
        self.tokens.append(Token(TokenType.EOF, "", self.line, self.column))
        return self.tokens

